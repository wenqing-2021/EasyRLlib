# this file is the configuration file for the training process
env_config:
  env_name: "CartPole-v1" # set the env_name

train_config:
  seed: 1
  epochs: 25
  total_steps: 1000000 # normally is 1e6
  num_envs: 4
  batch_size: 32 # if use on-policy algorithm, the batch_size is the same as the buffer_size
  buffer_size: 256 # if use the on-policy algorithm, the buffer_size would be int(total_steps/epochs/num_envs)

  off_policy_train_config:
    update_every: 25 # update the network every steps
    random_explor_steps: 20000 # random explore the env before the training
    soft_update_every: 100 # update the target network every steps
  
  on_policy_train_config:
    update_times: 80 # set the update_times, update the network times
    max_ep_len: 1000 # set the max_ep_len, the max length of the episode


agent_config_path: "src/config/agent_config/ppo.yaml"
exp_name: "DQN"
save_path: "output/"
device: "cpu" # set the device, "cuda" or "cpu"