# this file is the configuration file for the training process
env_config:
  env_name: "CartPole-v1"

train_config:
  seed: 1
  epochs: 125
  total_steps: 100000
  num_envs: 4
  batch_size: 64
  buffer_size: 256 # NOT used in on-policy training

  off_policy_train_config:
    update_every: 10
    random_explor_steps: 1000
    soft_update_every: 50
  
  on_policy_train_config:
    update_times: 80
    max_ep_len: 1000


agent_config_path: "src/config/agent_config/ppo.yaml"
exp_name: "PPO_test"
save_path: "output/"
device: "cuda"